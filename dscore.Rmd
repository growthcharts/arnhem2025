```{r echo=FALSE, warning=FALSE, message = FALSE, results="hide"}
source("R/before_chapter_script.R")
opts_chunk$set(echo = FALSE, warning=FALSE)
```

## The Dutch Development Instrument (DDI) {#sec:ddi}

The *Dutch Development Instrument* (DDI; in Dutch: *Van Wiechenschema*) is the standard instrument used to measure development during the ages 0-4 years. The DDI consists of [75 milestones](https://www.ncj.nl/van-wiechen/kenmerken/). The instrument assesses three developmental domains:

1.  Fine motor, adaptation, personality and social behaviour;
2.  Communication;
3.  Gross motor.

The milestones form two [sets](https://www.ggdghorkennisnet.nl/?file=656&m=1310474916&action=file.download), one for children aged 0-15 months, and another for children aged 15-54 months. The YHC professionals administer an age-appropriate subset of milestones at each of the scheduled visits, thus building a *longitudinal developmental profile* for each child.

### Description of SMOCC study {#sec:smocc}

The Social Medical Survey of Children Attending Child Health Clinics (SMOCC) study is a nationally representative cohort of 2,151 children born in The Netherlands during the years 1988--1989 [@herngreen1994]. The study monitored child development using observations made on the DDI during nine visits covering the first 24 months of life. The SMOCC study collected information during the first two years on 57 (out of 75) milestones.

The *standard* set in the DDI consists of relatively easy milestones that 90 per cent of the children can pass at the scheduled age. This set is designed to have maximal sensitivity for picking up delays in development. A distinctive feature of the SMOCC study was the inclusion of more difficult milestones beyond the standard set. The *additional* set originates from the next time point. The success rate on these milestones is about 50 per cent.

### Codebook of DDI 0-30 months

```{r smoccmodel, cache=TRUE}
data <- get_data(cohorts = 53)
items <- dscore::get_itemnames(data)
varlist <- list(adm = c("cohort", "subjid", "agedays"), 
                items = items,
                cov = NULL)
model <- suppressWarnings(dmetric::fit_dmodel(varlist, data, name = "57_0"))
```

```{r smoccitems}
meta <- dscore::get_itemtable(dscore::get_itemnames(instrument = "ddi")) %>%
  bind_cols(decompose_itemnames(.$item)) %>%   
  dplyr::select(item, domain, label) %>%
  mutate(domain = plyr::revalue(domain, c("cm" = "Communication", 
                                          "fm" = "Fine motor",
                                          "gm" = "Gross motor")))
df <- data.frame(
  item = dscore::get_itemnames(data),
  debut = c(1, 2, 3, 5, 6, 6, 7, 8, 9, 10, 10,
            4, 7, 8, 9,
            1, 2, 3, 3, 4, 5, 5, 5, 6, 7, 7, 8, 8, 9, 9, 10, 10, 10, 10, 
            4, 1, 1, 3, 4, 1, 3, 4, 4, 5, 5, 5, 6, 6, 6, 7, 7, 8, 8, 9, 10, 9, 9), 
  stringsAsFactors = FALSE)
meta <- df %>%  
  left_join(meta, by = "item") %>% 
  mutate(
    itemorder = dscore::order_itemnames(item, order = "idnm"), 
    debut = factor(debut, 
                   labels = c("1m", "2m", "3m", "6m", "9m", "12m", "15m", "18m", "24m", "30m"))
  ) %>% 
  arrange(debut, itemorder) %>% 
  dplyr::select(item, debut, domain, label)

# calculate visit from data
# meta <- data$itm %>%
#   group_by(item) %>% 
#   summarize(min_age = min(agedays, na.rm = TRUE)) %>% 
#   mutate(visit = cut(min_age, 
#                     breaks = c(18, 43, 76, 149, 216, 320, 399, 481, 633, 800),
#                     labels = c("1m", "2m", "3m", "6m", "9m", "12m", "15m", "18m", "24m"),
#                     right = FALSE),
#          wave = as.integer(visit)) %>% 
#   arrange(wave) %>% 
#   dplyr::select(item, visit) %>% 
#   left_join(meta, by = "item")

# options(knitr.table.format = "html") 
# kbl(meta, 
#     caption = "Codebook of DDI as used in the SMOCC study",
#     row.names = FALSE, 
#     col.names = c("Item", "Debut", "Domain", "Label"),
#     align = c("l", "r", "l", "l"),
#     booktabs = TRUE) %>%
#   kable_styling(latex_options = "scale_down") %>%
#   column_spec(column = 1, monospace = TRUE) %>% 
#   scroll_box(width = "100%", height = "300px")
ft <- flextable(meta)
ft <- set_header_labels(ft,
                        item = "Item",
                        debut = "Debut",
                        domain = "Domain",
                        label = "Label")
ft <- set_caption(ft, "Codebook of DDI as used in the SMOCC study")
ft <- set_table_properties(ft, layout = "autofit", width = .9)
ft <- font(ft, j = 1, fontname = "Courier")
ft <- align(ft, j = 2, align = "right")
knit_print(ft)
```

<br>

Table \@ref(tab:smoccitems) shows the 57 milestones from the DDI for ages 0 - 30 months as administered in the SMOCC study. Items are sorted according to *debut*, the age at which the item appears in the DDI. The response to each milestone is either a PASS (1) or a FAIL (0). Children who did not pass a milestone at the debut age were re-measured on that milestone during the next visit. The process continued until the child passed the milestone.

## Probability of passing a milestone given age {#sec:probage}

```{r smoccpa, fig.cap = '(ref:smoccpa)', fig.height = 4}
# define data for rug plot
data_rug <- data$itm %>%
  mutate(agemos = round(12 * agedays / 365.25), 3) %>%
  dplyr::select(item, value, agemos)

# calculate summary statistics
pass <- data_rug %>%
  mutate(agegp = cut(.data$agemos, breaks = seq(0, 60, 1))) %>%
  tidyr::drop_na(agegp) %>% 
  group_by(item, agegp) %>%
  summarise(p = round(100 * mean(.data$value, na.rm = TRUE)),
            a = mean(.data$agemos, na.rm = TRUE),
            n = n(), 
            .groups = "drop") %>%
  left_join(dscore::get_itemtable(items = items), by = "item") %>% 
  bind_cols(decompose_itemnames(.$item)) %>% 
  filter(n >= 5) %>%
  arrange(.data$item, a) %>%
  mutate(domain = plyr::revalue(domain, c("cm" = "Communication", 
                                          "fm" = "Fine motor",
                                          "gm" = "Gross motor")))

plot <- ggplot(pass, aes(a, p, group = item, colour = domain,
                         label = label)) +
  scale_x_continuous("Age (in months)", limits = c(0, 30),
                     breaks = seq(0, 28, 4)) +
  scale_y_continuous("% pass", breaks = seq(0, 100, 20),
                     limits = c(0, 100)) + 
  geom_line(size = 0.3) + 
  geom_point(size = 1.0)  +
  theme(legend.position = "none")

# if rendering HTML, add plotly tooltips
# https://github.com/rstudio/bookdown/issues/168
if (opts_knit$get("rmarkdown.pandoc.to") == "html") {
  plot <- suppressWarnings(plotly::ggplotly(plot, width = 700, height = 400, tooltip = c("item", "label")))
}

plot
```

(ref:smoccpa) Empirical percentage of passing each milestone in the DDI against age (Source: SMOCC data, $n$ = 2151, 9 occasions).

Figure \@ref(fig:smoccpa) summarizes the response obtained on each milestone as a curve against age. The percentage of pass scores increases with age for all milestones. Note that curves on the left have steeper slopes than those on the right, thus indicating that development is faster for younger children.

The domain determines the coloured (blue: gross motor, green: fine motor, red: communication). In general, domains are well mixed across age, though around some ages, e.g., at four months, multiple milestones from the same domain appear.

## Probability of passing a milestone given D-score {#sec:probd}

```{r smoccpd, fig.cap = '(ref:smoccpd)', fig.height = 4}
modelb <- model$dscore
delta <- dscore::get_tau(model$items, key = "", itembank = model$itembank)
data2 <- data$itm %>%
  filter(item %in% items) %>%
  left_join(data$visit, by = c("subjid", "agedays")) %>%
  left_join(modelb, by = c("subjid", "agedays")) %>%
  dplyr::select(subjid, agedays, item, value, d)

pass <- data2 %>% 
  tidyr::drop_na("value", "d") %>%
  mutate(dgp = cut(.data$d, breaks = seq(0, 70, 1)),
         agemos = round(.data$agedays / 365.25 * 12, 3)) %>%
  tidyr::drop_na(dgp) %>% 
  group_by(dgp, item) %>%
  summarise(
    p = round(100 * mean(.data$value, na.rm = TRUE)),
    a = mean(.data$agemos, na.rm = TRUE),
    d = mean(.data$d, na.rm = TRUE),
    n = n(), 
    .groups = "drop")
pass <- pass %>%
  left_join(model$itemtable, by = "item") %>%
  bind_cols(decompose_itemnames(.$item)) %>% 
  arrange(.data$item, dgp) %>%
  dplyr::select(item, dgp, a, d, p, n, domain, label) %>%
  filter(n >= 10 & p > 0 & p < 100) %>%
  mutate(domain = plyr::revalue(domain, c("cm" = "Communication", 
                                          "fm" = "Fine motor",
                                          "gm" = "Gross motor")))

plot <- ggplot(pass, aes(d, p, group = item, colour = domain, 
                         label = label)) +
  scale_x_continuous(paste0("D-score (", model$name,")"),
                     limits = c(0, 70),
                     breaks = seq(0, 70, 10)) +
  scale_y_continuous("% pass", breaks = seq(0, 100, 20),
                     limits = c(0, 100)) +
  geom_line(size = 0.3) + 
  geom_point(size = 1.0) +
  theme(legend.position = "none")

if (opts_knit$get("rmarkdown.pandoc.to") == "html") {
 plot <- suppressWarnings(plotly::ggplotly(plot, width = 700, height = 400, tooltip = c("item", "label")))
}
plot
```

(ref:smoccpd) Empirical percentage of passing each milestone in the DDI against the D-score (Source: SMOCC data, 2151 children, 9 occasions).

Figure \@ref(fig:smoccpd) is similar to Figure \@ref(fig:smoccpa), but with the horizontal axis replaced by the D-score. The D-score summarizes development into one number. See \@ref(sec:dscoreestimation) for a detailed explanation on how to calculate the D-score. The vertical axis with per cent pass is unchanged.

The percentage of successes increases with D-score for all milestones. In contrast to Figure \@ref(fig:smoccpa) all curves have a similar slope, a desirable property needed for an interval scale with a constant unit of measurement (c.f. Section \@ref(sec:unitbased)).

How can the relation between per cent pass and age be so different from the relation between per cent pass and the D-score? The next section explains the reason.

## Relation between age and the D-score {#sec:aged}

```{r smoccda, fig.cap = '(ref:smoccda)', fig.height = 6, warning = FALSE}
reference <- dplyr::select(dscore::get_reference(population = "dutch"), age, SDM2:SDP2) %>%
  mutate(month = age * 12) %>% 
  filter(month <= 30) %>%
  tidyr::gather(key = centile, value = d, -month, -age)
model$dscore$agemos <- round(model$dscore$agedays / 365.25 * 12, 3)
plot <-
  ggplot(reference, aes(x = month, y = d, group = centile)) +
  #  coord_fixed(ratio = 60/80 * 688/818) +
  scale_colour_manual(values = dmetric::get_palette("study", package = model$data_package),
                      na.value = "grey") +
  scale_x_continuous("Age (in months)",
                     limits = c(0, 30),
                     breaks = seq(0, 30, 6)) +
  scale_y_continuous(
    paste0("D-score (", model$name, ")"),
    breaks = seq(0, 70, 10),
    limits = c(-5, 75)
  ) +
  # geom_line(colour = get_palette("study", package = model$data_package)["GCDG-NLD-SMOCC"]) +
  geom_line(colour = "grey90") +
  geom_point(
    mapping = aes(
      x = agemos,
      y = d,
      group = cohort,
      colour = cohort
    ),
    data = model$dscore,
    size = 0.5,
    shape = 1
  ) +
  facet_wrap( ~ cohort, ncol = 4) +
  theme(legend.position = "none")
plot
```

(ref:smoccda) Relation between child D-score and child age in a cohort of Dutch children (Source: SMOCC data, $n$ = 2151, 9 occasions).

Figure \@ref(fig:smoccda) shows that the relation between D-score and age is nonlinear. Development in the first year is more rapid than in the second year. During the first year, infants gain about 40$D$, whereas in the second year they gain about 20$D$. A similar change in growth rate occurs in length (first year: 23 cm, second year: 12 cm, for Dutch children).

```{r smoccdap, warning = FALSE, fig.cap = '(ref:smoccdap)', }

if (opts_knit$get("rmarkdown.pandoc.to") == "html") {
  # model ICC curves D-score
  grid <- tidyr::crossing(
    item = items,
    d = seq(0, 70, 0.2))
  ib <- model$itembank %>%
    bind_cols(decompose_itemnames(.$item)) %>% 
    dplyr::select(item, domain, label, tau) %>% 
    mutate(domain = plyr::revalue(domain, c("cm" = "Communication", 
                                            "fm" = "Fine motor",
                                            "gm" = "Gross motor")))
  lms <- dscore::get_reference("dutch") %>% 
    mutate(month = age * 12) %>% 
    select(month, mu, sigma, nu, month)
  tab <- grid %>%
    left_join(ib, by = "item") %>%
    mutate(p = 100 * plogis(d, location = tau, scale = model$transform[2])) %>%
    filter(p > 1 & p < 99) %>%
    mutate(a = approx(x = lms$mu, 
                      y = lms$month, xout = d)$y) %>%
    tidyr::drop_na("a") %>%
    group_by(item)
  
  plot <- plotly::plot_ly(tab, x = ~a, y = ~d, z = ~p, color = ~domain, 
                          colors = scales::hue_pal()(3)) %>%
    plotly::add_lines() %>%
    plotly::hide_legend() %>% 
    plotly::layout(scene = list(xaxis = list(title = 'Age'),
                                yaxis = list(title = 'D'),
                                zaxis = list(title = '% pass'),
                                aspectratio = list(x = 1, y = 1, z = 0.5),
                                camera = list(
                                  up = list(
                                    x = 0,
                                    y = 1,
                                    z = 0
                                  ),
                                  eye = list(
                                    x = 0,
                                    y = 0,
                                    z = 2
                                  )
                                )
    )) %>% 
    plotly::layout(plot_bgcolor = 'transparent') %>% 
    plotly::layout(paper_bgcolor = 'transparent')
}

if (opts_knit$get("rmarkdown.pandoc.to") == "latex") {
  img <- magick::image_read(path = paste0("fig/scene", 1:3, ".pdf"))
  img[1] <- magick::image_scale(img[1], "550")
  orient3 <- magick::image_append(image = img)
  plot <- magick::image_write(orient3, "fig/scenes.pdf")
  plot <- include_graphics("fig/scenes.pdf")
}

if (!opts_knit$get("rmarkdown.pandoc.to") %in% c("html", "latex")) {
  plot <- include_graphics("fig/scenes.pdf")
}

plot
```

(ref:smoccdap) 3D-line graph illustrating how the patterns in Figures \@ref(fig:smoccpa) and \@ref(fig:smoccpd) induce the curvature in the relation between D-score and age. The printed version shows three orientations of the relation between age, percent pass and D-score. The online version holds an interactive 3D graph that the reader can actively manipulate the orientation of the graph by click-hold-drag mouse operations.

Figure \@ref(fig:smoccdap) shows the mutual relations between age, percentage of milestone passing and the D-score. There are three main orientations.

-   In the default orientation (age on the horizontal axis, D-score on the vertical axis), we see a curvilinear relation between the age and item difficulty.
-   Rotate the graph (age on the horizontal axis, passing percentage on the vertical axis). Observe that this is the same pattern as in Figure \@ref(fig:smoccpa) (with *unequal slopes*). Curves are coloured by domain.
-   Rotate the graph (D-score on the horizontal axis, passing percentage on the vertical axis). Observe that this pattern is the same as in Figure \@ref(fig:smoccpd) (with *equal slopes*).

All patterns can co-exist because of the curvature in the relation between D-score and age. The curvature is never explicitly modelled or defined, but a consequence of the equal-slopes assumption in the relation between the D-score and the passing percentage of a milestone.

## Measurement model for the D-score {#sec:measurementmodel}

### What are measurement models?

From section \@ref(sec:whatismeasurement) we quote:

> The measurement model specifies the relations between the data and the latent variable.

The term *Item Response Theory* (IRT) refers to the scientific theory of measurement models. Good introductory works include @wright1982, @embretsen2000 and @engelhard2013.

IRT models enable quantification of the locations of both *items (milestones) and* persons\* on the latent variable. We reserve the term *item* for generic properties, and *milestone* for child development. In general, items are part of the measurement instrument, persons are the objects to be measured.

An IRT model has three major structural components:

-   Specification of the underlying *latent variable(s)*. In this work, we restrict ourselves to models with just one latent variable. Multi-dimensional IRT models do have their uses, but they are complicated to fit and not widely used;
-   For a given item, a specification of the *probability of success* given a value on the latent variables. This specification can take many forms. Section \@ref(sec:itemresponsefunctions) focuses on this in more detail;
-   Specification how probability models for the different items should be combined. In this work, we will restrict to models that assume *local independence* of the probabilities. In that case, the probability of passing two items is equal to the product of success probabilities.

### Adapt the model? Or adapt the data? {#sec:adaptmodel}

The measurement model induces a predictable pattern in the observed items. We can test this pattern against the observed data. When there is misfit between the expected and observed data, we can follow two strategies:

-   Make the measurement model more general;
-   Discard items (and sometimes persons) to make the model fit.

These are very different strategies that have led to heated debates among psychometricians. See @engelhard2013 for an overview.

In this work, we opt for the - rigorous - Rasch model (@rasch1960) and will adapt the data to reduce discrepancies between model and data. Arguments for this choice are given later, in Section \@ref(sec:whyrasch).

## Item response functions {#sec:itemresponsefunctions}

Most measurement models describe the probability of passing an item as a function of the *difference* between the person's ability and the item's difficulty. A person with low ability will almost inevitably fail a heavy item, whereas a highly able person will almost surely pass an easy item.

Let us now introduce a few symbols. We adopt the notation used in @wright1982. We use $\beta_n$ (ability) to refer to the true (but unknown) developmental score of child $n$. Symbol $\delta_i$ (difficulty) is the true (but unknown) difficulty of an item $i$, and $\pi_{ni}$ is the probability that child $n$ passes item $i$. See Appendix A for a complete list.

The difference between the ability of child $n$ and difficulty of item $i$ is

$$\beta_n - \delta_i$$

In the special case that $\beta_n = \delta_i$, the person will have a probability of 0.5 of passing the item.

### Logistic model

A widely used method is to express differences on the latent scale in terms of *logistic units* (or *logits*) [@berkson1944]. The reason preferring the logistic over the linear unit is that its output returns a probability value that maps to discrete events. In our case, we can describe the probability of passing an item (milestone) as a function of the difference between $\beta_n$ and $\delta_i$ expressed in logits.

```{r logisticplot, warning = FALSE, fig.asp = 0.5, fig.cap = '(ref:logisticplot)', width = "80%"}
pkg <- c("ggplot2", "RColorBrewer")
loaded <- sapply(pkg, require, character.only = TRUE, 
                 warn.conflicts = FALSE, quietly = TRUE)
options(knitr.kable.NA = "?")

x <- seq(-5, 5, 0.25)
items <- data.frame(
  Items = c(rep(c("C", "B", "A", "D", "E"), times = c(4, 2, length(x), length(x), length(x)))),
  beta = c(-5, 1, 1, +5,  -5,  +5, x, x, x),
  pass = c( 0, 0, 1,  1, 0.3, 0.3,
            plogis(x),
            plogis(0.6 * (x + 1)),
            smooth.spline(x = x, y = plogis(c(x[1:15], rep(x[16], 10), x[26:41])), df = 8)$y))
ggplot(subset(items, Items == "A"), aes(x = beta, y = 100 * pass, group = Items, colour = Items)) +
  geom_line(lwd = 0.55) + 
  scale_x_continuous("logits", breaks = -5:5) + 
  scale_y_continuous("% pass", breaks = seq(0, 100, 20), limits = c(0, 100)) +
  scale_colour_brewer(palette = "Set1", labels = c("A: Logistic", "B: Constant", "C: Step", "D: 2PL", "E: Monotone")) + 
  theme(legend.position = c(0.05, 0.95), legend.justification = c(0, 1))
```

(ref:logisticplot) Standard logistic curve. Percentage of children passing an item for a given ability-difficulty gap $\beta_n - \delta_i$.

Figure \@ref(fig:logisticplot) shows how the percentage of children that pass the item varies in terms of the ability-difficulty gap $\beta_n - \delta_i$. The gap can vary either by $\beta_n$ or $\delta_i$ so that we may use the graph in two ways:

-   To find the probability of passing items with various difficulties for a child with ability $\beta_n$. If $\delta_i = \beta_n$ then $\pi_{ni} = 0.5$. If $\delta_i < \beta_n$ then $\pi_{ni} > 0.5$, and if $\delta_i > \beta_n$ then $\pi_{ni} < 0.5$. In words: If the difficulty of the item is equal to the child's ability, then the child has a 50/50 chance to pass. The child will have a higher than 50/50 chance of passing for items with lower difficulty and have a lower than 50/50 chance of passing for items with difficulties that exceed the child's ability.
-   To find the probability of passing a given item $\delta_i$ for children that vary in ability. If $\beta_n < \delta_i$ then $\pi_{ni} < 0.5$, and if $\beta_n > \delta_i$ then $\pi_{ni} > 0.5$. In words: Children with abilities lower than the item's difficulty will have lower than 50/50 chance of passing, whereas children with abilities that exceed the item's difficulty will have a higher than 50/50 chance of passing.

Formula \@ref(eq:logistic) defines the standard logistic curve:

```{=tex}
\begin{equation}
\pi_{ni} = \frac{\exp(\beta_n - \delta_i)}{1+\exp(\beta_n -\delta_i)} (\#eq:logistic)
\end{equation}
```
One way to interpret the formula is as follows. The logarithm of the odds that a person with ability $\beta_n$ passes an item of difficulty $\delta_i$ is equal to the difference $\beta_n-\delta_i$ [@wright1982]. For example, suppose that the probability that person $n$ passes milestone $i$ is $\pi_{ni} = 0.5$. In that case, the odds of passing is equal to $0.5 / (1-0.5) = 1$, so $\log(1) = 0$ and thus $\beta_n = \delta_i$. If $\beta_n - \delta_i = \log(2) = 0.693$ person $n$ is *two* times more likely to pass than to fail. Likewise, if the difference is $\beta_n - \delta_i = \log(3) = 1.1$, then person $n$ is *three* more likely to pass. And so on.

### Types of item response functions

The standard logistic function is by no means the only option to map the relationship between the latent variable and the probability of passing an item. The logistic function is the dominant choice in IRT, but it is instructive to study some other mappings. The *item response function* maps success probability against ability.

```{r irfplot, warning = FALSE, fig.asp = 0.5, fig.cap = '(ref:irfplot)'}
ggplot(items, aes(x = beta, y = 100 * pass, group = Items, colour = Items)) +
  geom_line(lwd = 0.75) + 
  scale_x_continuous("Child ability (logits)", breaks = -5:5) + 
  scale_y_continuous("% pass", breaks = seq(0, 100, 20), limits = c(0, 100)) +
  scale_colour_brewer(palette = "Set1", labels = c("A: Logistic", "B: Constant", "C: Step", "D: 2PL", "E: Monotone")) + 
  theme(legend.position = c(0.05, 0.95), legend.justification = c(0, 1))
```

(ref:irfplot) Item response functions for five hypothetical items, each demonstrating a positive relation between ability and probability to pass.

Figure \@ref(fig:irfplot) illustrates several other possibilities. Let us consider five hypothetical items, A-E. Note that the horizontal axis now refers to the ability, instead of the ability-item gap in \@ref(fig:logisticplot).

-   A: Item A is the logistic function discussed in Section \@ref(sec:itemresponsefunctions).
-   B: For item B, the probability of passing is constant at 30 per cent. This 30 per cent is not related to ability. Item B does not measure ability, only adds to the noise, and is of low quality.
-   C: Item C is a step function centred at an ability level of 1, so *all* children with an ability below 1 logit fail and *all* children with ability above 1 logit pass. Item C is the ideal item for discriminating children with abilities above and below 1. The item is not sensitive to differences at other ability levels, and often not so realistic in practice.
-   D: Like A, item D is a smoothly increasing logistic function, but it has an extra parameter that allows it to vary its slope (or discrimination). The extra parameter can make the curve steeper (more discriminatory) than the red curve, in the limit approaching a step curve. It can also become shallower (less discriminatory) than the red curve (as plotted here), in the limit approaching a constant curve (item B). Thus, item D generalizes items A, B or C.
-   E: Item E is even more general in the sense that it need not be logistic, but a general monotonically increasing function. As plotted, the item is insensitive to abilities between -1 and 0 logits, and more sensitive to abilities between 0 to 2 logits.

These are just some examples of how the relationship between the child's ability and passing probability could look. In practice, the curves need not start at 0 per cent or end at 100 per cent. They could also be U-shaped, or have other non-monotonic forms. See @coombs1964 for a thorough overview of such models. In practice, most models are restricted to shapes A-D.

### Person response functions

We can reverse the roles of persons and items. The *person response function* tells us how likely it is that a single person can pass an item, or more commonly, a set of items.

Let us continue with items A, C and D from Figure \@ref(fig:irfplot), and calculate the response function for three children, respectively with abilities $\beta_1 = -2$, $\beta_2 = 0$ and $\beta_3 = 2$.

```{r prfplot, warning = FALSE, fig.asp = 0.5, fig.cap = '(ref:prfplot)'}
x <- c(seq(-5.00, -2.25, 0.25), -2.001, -2, -1.999, 
       seq(-1.75, -0.25, 0.25), -0.001,  0,  0.001,
       seq( 0.25,  1.75, 0.25),  1.999,  2,  2.001,
       seq( 2.25,  5.00, 0.25))
A1 <- c(rep(1, 23), 0.5, rep(0, 23))
C1 <- 1 - plogis(x)
D1 <- 1 - plogis(0.6 * (x + 1))
ACD1 <- (A1 + C1 + D1) / 3

A2 <- c(rep(1, 33), 0.5, rep(0, 13))
C2 <- 1 - plogis(x - 2)
D2 <- 1 - plogis(0.6 * (x - 1))
ACD2 <- (A2 + C2 + D2) / 3

A3 <- c(rep(1, 13), 0.5, rep(0, 33))
C3 <- 1 - plogis(x + 3)
D3 <- 1 - plogis(0.6 * (x + 4))
ACD3 <- (A3 + C3 + D3) / 3

data <- data.frame(delta = x,
                   person = rep(c("-2", "0", "+2"), each = 47),
                   pass = c(ACD3, ACD1, ACD2))
ggplot(data, aes(x = delta, y = 100 * pass, group = person, colour = person)) +
  geom_line(lwd = 0.75) + 
  scale_x_continuous("Item difficulty (logits)", breaks = -5:5) + 
  scale_y_continuous("% pass", breaks = seq(0, 100, 20), limits = c(0, 100)) +
  scale_colour_brewer(name = "Person ability", palette = "Set1", limits = c("-2", "0", "+2")) + 
  theme(legend.position = c(0.8, 0.6), legend.justification = c(0, 0)) +
  annotate("text", x = -4.5, y = 15, label = "Easy items", fontface = "bold") + 
  annotate("text", x =  4.5, y = 15, label = "Hard items", fontface = "bold")
```

(ref:prfplot) Person response functions for three children with abilities -2, 0 and +2, using a small test of items A, C and D.

Figure \@ref(fig:prfplot) presents the person response functions from three persons with abilities of -2, 0 and +2 logits. We calculate the functions as the average of response probabilities on items A, C and D. Thus, on average, we expect that child 1 logit will pass an easy item of difficulty -3 in about 60 per cent of the time, whereas for an intermediate item of difficulty of -1 the passing probability would be 10 per cent. For child 3, with higher ability, these probabilities are quite different: 97% and 90%. The substantial drop in the middle of the curve is due to the step function of item A.

## Engelhard criteria for invariant measurement {#sec:engelhard}

In this work, we strive to achieve *invariant measurement*, a strict form of measurements that is subject to the following requirements [@engelhard2013, p. 14]:

1.  *Item-invariant measurement of persons*: The measurement of persons must be independent of the particular items used for the measuring.
2.  *Non-crossing person response functions*: A more able person must always have a better chance of success on an item that a less able person.
3.  *Person-invariant calibration of test items*: The calibration of the items must be independent of the particular persons used for calibration.
4.  *Non-crossing item response functions*: Any person must have a better chance of success on an easy item than on a more difficult item.
5.  *Unidimensionality*: Items and persons take on values on a *single* latent variable. Under this assumption, the relations between the items are fully explainable by the scores on the latent scale. In practice, the requirement implies that items should measure the same construct. [@hattie1985]

Three families of IRT models support invariant measurement:

1.  Scalogram model [@guttman1950]
2.  Rasch model [@rasch1960; @andrich1978; @wright1982]
3.  Mokken scaling model [@mokken1971; @molenaar1997]

The Guttman and Mokken models yield an ordinal latent scale, while the Rasch model yields an interval scale (with a constant unit).

## Why take the Rasch model? {#sec:whyrasch}

-   *Invariant measurement*: The Rasch model meets the five Engelhard criteria (c.f. Section \@ref(sec:engelhard)).
-   *Interval scale*: When it fits, the Rasch model provides an interval scale, the de-facto requirement for any numerical comparisons (c.f. Section \@ref(sec:motivationunit)).
-   *Parsimonious*: The Rasch model has one parameter for each item and one parameter for each person. The Rash model one of the most parsimonious IRT models, and can easily be applied to thousands of items and millions of persons.
-   *Specific objectivity*: Person and item parameters are mathematically separate entities in the Rasch model. In practice, this means that the estimated difference in ability between two persons does not depend on the difficulty of the test. Also, the estimated differences in difficulties between two items do not depend on the abilities in the calibration sample. The property is especially important in the analysis of combined data, where abilities can vary widely between sources. See @rasch1977 for derivations and examples.
-   *Unified model*: The Rasch model unifies distinct traditions in measurement theory. One may derive the Rasch model from
    -   [Thorndike's 1904 criteria](https://www.rasch.org/rmt/rmt143g.htm)
    -   [Guttman scalogram model](https://www.rasch.org/rmt/rmt63e.htm)
    -   [Ratio-scale counts](https://www.rasch.org/rmt/rmt62c.htm)
    -   [Raw scores as sufficient statistics](https://www.rasch.org/rmt/rmt32e.htm)
    -   [Thurstone's scaling requirements](https://www.rasch.org/rmt/rmt21a.htm)
    -   [Campbell concatenation](https://www.rasch.org/rmt/rmt21b.htm)
    -   [Rasch's specific objectivity](https://www.rasch.org/rmt/rmt11a.htm)
-   *Fits child development data*: Last but not least, as we will see in Section \@ref(ch:evaluation), the Rasch model provides an excellent fit to child development milestones.
